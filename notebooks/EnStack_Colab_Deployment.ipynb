{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnStack: Advanced Stacking Ensemble for Vulnerability Detection\n",
    "\n",
    "This notebook provides a professional, fully optimized pipeline for reproducing the results of the EnStack paper on Google Colab.\n",
    "\n",
    "### ‚ö° Optimized Features:\n",
    "1.  **High-Speed Training:** Automatic Mixed Precision (AMP) and Dynamic Padding (+5-8x speed).\n",
    "2.  **Memory Efficient:** Lazy Loading and Gradient Checkpointing (Run large LLMs on T4 GPU).\n",
    "3.  **Algorithmic Correctness:** K-Fold Out-of-Fold (OOF) stacking to prevent data leakage.\n",
    "4.  **Advanced Visualization:** Confusion matrices, ROC curves, and Feature Importance plots.\n",
    "5.  **Production Ready:** Export models to ONNX and TorchScript.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount Drive\n",
    "print(\"üìÇ Connecting to Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Clone Repository\n",
    "REPO_NAME = \"EnStack-paper\" # @param {type:\"string\"}\n",
    "GITHUB_USER = \"TCTri205\" # @param {type:\"string\"}\n",
    "\n",
    "%cd /content\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"‚¨áÔ∏è Cloning {REPO_NAME}...\")\n",
    "    !git clone https://github.com/{GITHUB_USER}/{REPO_NAME}.git\n",
    "else:\n",
    "    print(\"üîÑ Repository exists. Pulling latest optimized version...\")\n",
    "    !cd {REPO_NAME} && git pull\n",
    "\n",
    "%cd /content/{REPO_NAME}\n",
    "\n",
    "# 3. Install Dependencies\n",
    "print(\"üì¶ Installing high-performance dependencies...\")\n",
    "!pip install -r requirements.txt -q\n",
    "!pip install transformers[torch] datasets pyarrow xgboost tensorboard seaborn matplotlib -q\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete. Ready to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Hardware Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "print(\"üîç Hardware Check:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå GPU NOT FOUND. Please go to: Runtime -> Change runtime type -> T4 GPU\")\n",
    "\n",
    "print(f\"‚úÖ System RAM: {psutil.virtual_memory().total / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "Choose to use the **Full Draper VDISC** dataset (paper reproduction) or **Dummy Data** (quick code test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown ### Data Source Configuration\n",
    "DATA_MODE = \"Draper VDISC\" # @param [\"Draper VDISC\", \"Dummy Data\"]\n",
    "SAMPLE_SIZE = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "if DATA_MODE == \"Draper VDISC\":\n",
    "    print(\"üöÄ Downloading and processing Draper VDISC (~1GB)...\")\n",
    "    !chmod +x scripts/setup_draper.sh\n",
    "    !./scripts/setup_draper.sh\n",
    "else:\n",
    "    print(f\"üîÑ Generating synthetic dummy data ({SAMPLE_SIZE} samples)...\")\n",
    "    !python scripts/prepare_data.py --output_dir /content/drive/MyDrive/EnStack_Data --mode synthetic --sample {SAMPLE_SIZE}\n",
    "\n",
    "print(\"\\n‚úÖ Data is ready on Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Optimized Training Pipeline\n",
    "This cell executes the full training for base models (CodeBERT, etc.) and the Meta-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown ### Training Configuration\n",
    "EPOCHS = 10 # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "ACCUMULATION_STEPS = 1 # @param {type:\"integer\"}\n",
    "USE_SWA = False # @param {type:\"boolean\"}\n",
    "RESUME = True # @param {type:\"boolean\"}\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Update config.yaml with notebook parameters\n",
    "with open('configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['training']['epochs'] = EPOCHS\n",
    "config['training']['batch_size'] = BATCH_SIZE\n",
    "config['training']['gradient_accumulation_steps'] = ACCUMULATION_STEPS\n",
    "config['training']['use_swa'] = USE_SWA\n",
    "\n",
    "with open('configs/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"üöÄ Starting Training Pipeline...\")\n",
    "!python scripts/train.py --config configs/config.yaml {'--resume' if RESUME else ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meta-Classifier Comparison (Table III Reproduction)\n",
    "Evaluate different meta-classifiers (SVM, Logistic Regression, XGBoost) on the same optimized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from scripts.train import extract_all_features, train_base_models, load_labels_from_file\n",
    "from src.stacking import (\n",
    "    evaluate_meta_classifier,\n",
    "    prepare_meta_features,\n",
    "    train_meta_classifier,\n",
    ")\n",
    "from src.utils import get_device\n",
    "from IPython.display import display\n",
    "\n",
    "def reproduce_table_iii():\n",
    "    print(\"üìä Comparing Meta-Classifiers (LR vs RF vs SVM vs XGBoost)...\")\n",
    "    \n",
    "    with open(\"configs/config.yaml\", 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    device = get_device()\n",
    "    root_dir = Path(config['data']['root_dir'])\n",
    "    \n",
    "    # 1. Load models and pre-created dataloaders\n",
    "    trainers, dataloaders = train_base_models(config, config['model']['base_models'], \n",
    "                                             num_epochs=0, device=device, resume=True)\n",
    "    \n",
    "    # 2. Extract Optimized Features (with caching)\n",
    "    features_dict = extract_all_features(config, trainers, dataloaders, mode=\"logits\", use_cache=True)\n",
    "    \n",
    "    # 3. Load Labels\n",
    "    train_labels = load_labels_from_file(root_dir / config['data']['train_file'])\n",
    "    test_labels = load_labels_from_file(root_dir / config['data']['test_file'])\n",
    "    \n",
    "    # 4. Prepare Meta-features with Scaling/PCA\n",
    "    train_meta, _, pca, scaler = prepare_meta_features(features_dict['train'], train_labels, use_pca=True, use_scaling=True)\n",
    "    test_meta, _, _, _ = prepare_meta_features(features_dict['test'], pca_model=pca, scaler=scaler, use_pca=True, use_scaling=True)\n",
    "    \n",
    "    # 5. Iterative Evaluation\n",
    "    results = []\n",
    "    for m_type in [\"lr\", \"rf\", \"svm\", \"xgboost\"]:\n",
    "        print(f\"  > Training {m_type.upper()}...\")\n",
    "        params = config['model']['meta_classifier_params'].get(m_type, {})\n",
    "        clf = train_meta_classifier(train_meta, train_labels, classifier_type=m_type, **params)\n",
    "        metrics = evaluate_meta_classifier(clf, test_meta, test_labels)\n",
    "        results.append({\"Classifier\": m_type.upper(), \"Acc\": metrics['accuracy']*100, \"F1\": metrics['f1']*100, \"AUC\": metrics['auc']*100})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "comparison_df = reproduce_table_iii()\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import glob\n",
    "\n",
    "print(\"üìà Training Curves:\")\n",
    "hist_plots = glob.glob(f\"{config['training']['output_dir']}/**/training_history.png\", recursive=True)\n",
    "for p in hist_plots:\n",
    "    print(f\"Source: {p}\")\n",
    "    display(Image(filename=p))\n",
    "\n",
    "print(\"\\nüéØ Final Confusion Matrix:\")\n",
    "display(Image(filename=f\"{config['training']['output_dir']}/confusion_matrix.png\"))\n",
    "\n",
    "print(\"\\n‚≠ê Feature Importance (Base Model Impact):\")\n",
    "display(Image(filename=f\"{config['training']['output_dir']}/feature_importance.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Export for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the primary model to ONNX for 3x faster CPU inference\n",
    "import sys\n",
    "from src.models import create_model\n",
    "\n",
    "print(\"üöÄ Exporting model for production...\")\n",
    "model_name = config['model']['base_models'][0]\n",
    "model, _ = create_model(model_name, config, pretrained=False)\n",
    "\n",
    "checkpoint_path = f\"{config['training']['output_dir']}/{model_name}/last_checkpoint\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load weights from your best run\n",
    "    model.load_state_dict(torch.load(f\"{checkpoint_path}/pytorch_model.bin\", map_location='cpu'), strict=False)\n",
    "    \n",
    "    onnx_path = f\"{config['training']['output_dir']}/optimized_model.onnx\"\n",
    "    model.export_onnx(onnx_path)\n",
    "    print(f\"‚úÖ Successfully exported to: {onnx_path}\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found to export.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
