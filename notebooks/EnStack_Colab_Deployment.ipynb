{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnStack: Google Colab Deployment\n",
    "\n",
    "This notebook automates the setup and execution of the EnStack project on Google Colab.\n",
    "\n",
    "### Prerequisite\n",
    "1. Create a folder named `EnStack_Data` in your Google Drive root.\n",
    "2. Upload your data files (`train_processed.pkl`, `val_processed.pkl`, `test_processed.pkl`) into that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"üìÇ Connecting to Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify Drive connection\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"‚úÖ Google Drive connected successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to connect to Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository\n",
    "Choose **Public** if your repo is open, or **Private** if you need a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# @markdown ### Repository Settings\n",
    "REPO_TYPE = \"Public\" # @param [\"Public\", \"Private\"]\n",
    "USERNAME = \"TCTri205\" # @param {type:\"string\"}\n",
    "REPO_NAME = \"EnStack-paper\" # @param {type:\"string\"}\n",
    "\n",
    "# Construct URL\n",
    "if REPO_TYPE == \"Public\":\n",
    "    REPO_URL = f\"https://github.com/{USERNAME}/{REPO_NAME}.git\"\n",
    "else:\n",
    "    print(\"üîë Enter your Personal Access Token (PAT):\")\n",
    "    token = getpass()\n",
    "    REPO_URL = f\"https://{token}@github.com/{USERNAME}/{REPO_NAME}.git\"\n",
    "\n",
    "# Clone\n",
    "%cd /content\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"‚¨áÔ∏è Cloning {REPO_NAME}...\")\n",
    "    !git clone {REPO_URL}\n",
    "else:\n",
    "    print(\"üîÑ Repository exists. Pulling latest changes...\")\n",
    "    !cd {REPO_NAME} && git pull\n",
    "\n",
    "# Change directory to project root\n",
    "%cd /content/{REPO_NAME}\n",
    "print(f\"‚úÖ Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Install additional useful packages for Colab\n",
    "!pip install pyyaml tqdm scikit-learn transformers torch -q\n",
    "\n",
    "print(\"‚úÖ Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download & Prepare Real Data (Draper VDISC)\n",
    "This step downloads the dataset from Hugging Face and processes it into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable sample size (set to 0 or None for full dataset)\n",
    "SAMPLE_SIZE = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "print(f\"üîÑ Downloading and processing data (Sample size: {SAMPLE_SIZE})...\")\n",
    "if SAMPLE_SIZE > 0:\n",
    "    !python scripts/prepare_data.py --output_dir /content/drive/MyDrive/EnStack_Data --sample {SAMPLE_SIZE}\n",
    "else:\n",
    "    !python scripts/prepare_data.py --output_dir /content/drive/MyDrive/EnStack_Data\n",
    "\n",
    "print(\"‚úÖ Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "CONFIG_PATH = \"configs/config.yaml\"\n",
    "\n",
    "# Load config\n",
    "if os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    data_root = config['data']['root_dir']\n",
    "    print(f\"üîç Configured data path: {data_root}\")\n",
    "    \n",
    "    if os.path.exists(data_root):\n",
    "        print(\"‚úÖ Data directory found on Drive!\")\n",
    "        print(\"   Files:\", os.listdir(data_root))\n",
    "    else:\n",
    "        print(f\"‚ùå Directory '{data_root}' not found.\")\n",
    "        print(\"‚ö†Ô∏è Please ensure you created 'EnStack_Data' in MyDrive and uploaded your .pkl files.\")\n",
    "else:\n",
    "    print(\"‚ùå config.yaml not found. Did the repo clone correctly?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main training script\n",
    "!python scripts/train.py --config configs/config.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
