{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnStack: Google Colab Deployment\n",
    "\n",
    "This notebook automates the setup and execution of the EnStack project on Google Colab.\n",
    "\n",
    "### Prerequisite\n",
    "1. Create a folder named `EnStack_Data` in your Google Drive root.\n",
    "2. Upload your data files (`train_processed.pkl`, `val_processed.pkl`, `test_processed.pkl`) into that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"üìÇ Connecting to Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify Drive connection\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"‚úÖ Google Drive connected successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to connect to Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository\n",
    "Choose **Public** if your repo is open, or **Private** if you need a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# @markdown ### Repository Settings\n",
    "REPO_TYPE = \"Public\" # @param [\"Public\", \"Private\"]\n",
    "USERNAME = \"TCTri205\" # @param {type:\"string\"}\n",
    "REPO_NAME = \"EnStack-paper\" # @param {type:\"string\"}\n",
    "\n",
    "# Construct URL\n",
    "if REPO_TYPE == \"Public\":\n",
    "    REPO_URL = f\"https://github.com/{USERNAME}/{REPO_NAME}.git\"\n",
    "else:\n",
    "    print(\"üîë Enter your Personal Access Token (PAT):\")\n",
    "    token = getpass()\n",
    "    REPO_URL = f\"https://{token}@github.com/{USERNAME}/{REPO_NAME}.git\"\n",
    "\n",
    "# Clone\n",
    "%cd /content\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"‚¨áÔ∏è Cloning {REPO_NAME}...\")\n",
    "    !git clone {REPO_URL}\n",
    "else:\n",
    "    print(\"üîÑ Repository exists. Pulling latest changes...\")\n",
    "    !cd {REPO_NAME} && git pull\n",
    "\n",
    "# Change directory to project root\n",
    "%cd /content/{REPO_NAME}\n",
    "print(f\"‚úÖ Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"üîç Checking GPU availability...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected. Training will be VERY slow on CPU.\")\n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT: Enable GPU for faster training:\")\n",
    "    print(\"   1. Go to Runtime ‚Üí Change runtime type\")\n",
    "    print(\"   2. Select Hardware accelerator: T4 GPU\")\n",
    "    print(\"   3. Click Save and restart the notebook\\n\")\n",
    "    \n",
    "    # Ask user if they want to continue\n",
    "    import time\n",
    "    print(\"‚è≥ Waiting 10 seconds... Press 'Stop' button if you want to enable GPU first.\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Install additional useful packages for Colab\n",
    "!pip install pyyaml tqdm scikit-learn transformers torch -q\n",
    "\n",
    "print(\"‚úÖ Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download & Prepare Real Data\n",
    "This step downloads a public vulnerability dataset and processes it into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown ### Data Configuration\n",
    "# @markdown Choose data source:\n",
    "# @markdown - **auto**: Try public dataset, fallback to synthetic\n",
    "# @markdown - **public**: Use code_x_glue_cc_defect_detection\n",
    "# @markdown - **synthetic**: Generate test data\n",
    "# @markdown - **manual**: Show instructions for uploading Draper VDISC\n",
    "\n",
    "DATA_MODE = \"auto\" # @param [\"auto\", \"public\", \"synthetic\", \"manual\"]\n",
    "SAMPLE_SIZE = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "print(f\"üîÑ Preparing data (Mode: {DATA_MODE}, Sample size: {SAMPLE_SIZE})...\")\n",
    "!python scripts/prepare_data.py --output_dir /content/drive/MyDrive/EnStack_Data --mode {DATA_MODE} --sample {SAMPLE_SIZE}\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "CONFIG_PATH = \"configs/config.yaml\"\n",
    "\n",
    "# Load config\n",
    "if os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    data_root = config['data']['root_dir']\n",
    "    print(f\"üîç Configured data path: {data_root}\")\n",
    "    \n",
    "    if os.path.exists(data_root):\n",
    "        print(\"‚úÖ Data directory found on Drive!\")\n",
    "        print(\"   Files:\", os.listdir(data_root))\n",
    "    else:\n",
    "        print(f\"‚ùå Directory '{data_root}' not found.\")\n",
    "        print(\"‚ö†Ô∏è Please ensure you created 'EnStack_Data' in MyDrive and uploaded your .pkl files.\")\n",
    "else:\n",
    "    print(\"‚ùå config.yaml not found. Did the repo clone correctly?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown ### Training Configuration\n",
    "# @markdown Reduce epochs for faster testing (default is 10 in config.yaml)\n",
    "\n",
    "EPOCHS = 2 # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "\n",
    "print(f\"üìã Training will use: {EPOCHS} epochs, batch size {BATCH_SIZE}\")\n",
    "print(f\"‚è±Ô∏è  Estimated time per epoch: ~5-10 minutes on GPU, ~30-60 minutes on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main training script with custom parameters\n",
    "!python scripts/train.py --config configs/config.yaml --epochs {EPOCHS} --batch-size {BATCH_SIZE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
