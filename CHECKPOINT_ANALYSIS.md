# Checkpoint v√† Resume Training - Ph√¢n t√≠ch v√† S·ª≠a l·ªói

## V·∫•n ƒë·ªÅ b√°o c√°o:
User b√°o r·∫±ng ƒë√£ train xong epoch 1 v√† ƒë√£ b·∫Øt ƒë·∫ßu epoch 2 (kho·∫£ng 8/1270 batches), sau ƒë√≥ d·ª´ng v√† resume. Nh∆∞ng khi resume, checkpoint hi·ªÉn th·ªã `epoch=1, step=1000` v√† training ch·∫°y l·∫°i epoch 1 t·ª´ step 1000.

## Ph√¢n t√≠ch chi ti·∫øt:

### 1. C∆° ch·∫ø l∆∞u checkpoint

Code c√≥ 2 ƒëi·ªÉm l∆∞u checkpoint:

**A. Mid-epoch checkpoint** (src/trainer.py:320-321):
```python
if (step + 1) % save_steps == 0:
    self.save_checkpoint("last_checkpoint", epoch=epoch, step=(step + 1))
```
- L∆∞u m·ªói 500 steps (default save_steps=500)
- Epoch 1: L∆∞u t·∫°i step 500, 1000 (ghi ƒë√® l√™n file `last_checkpoint`)

**B. End-of-epoch checkpoint** (src/trainer.py:646):
```python
self.save_checkpoint("last_checkpoint", epoch=epoch, step=0)
```
- L∆∞u khi epoch ho√†n th√†nh
- `step=0` ƒë√°nh d·∫•u epoch ƒë√£ xong

### 2. V·∫•n ƒë·ªÅ ph√°t hi·ªán ƒë∆∞·ª£c:

#### **V·∫•n ƒë·ªÅ #1: Checkpoint c√≥ th·ªÉ b·ªã ghi ƒë√®**
C·∫£ mid-epoch v√† end-of-epoch ƒë·ªÅu l∆∞u v√†o c√πng file `last_checkpoint`, d·∫´n ƒë·∫øn:
- Checkpoint cu·ªëi epoch C√ì TH·ªÇ b·ªã ghi ƒë√® b·ªüi checkpoint mid-epoch c·ªßa epoch ti·∫øp theo
- N·∫øu c√≥ l·ªói gi·ªØa validation v√† save checkpoint, checkpoint cu·ªëi epoch kh√¥ng ƒë∆∞·ª£c l∆∞u

#### **V·∫•n ƒë·ªÅ #2: Kh√¥ng c√≥ error handling khi save checkpoint**
```python
self.model.save_pretrained(str(save_path))  # C√≥ th·ªÉ fail
torch.save(state_dict, save_path / "training_state.pth")  # C√≥ th·ªÉ fail
```
N·∫øu fail, checkpoint b·ªã corrupt ho·∫∑c kh√¥ng ƒë∆∞·ª£c l∆∞u, nh∆∞ng code kh√¥ng b√°o l·ªói r√µ r√†ng.

#### **V·∫•n ƒë·ªÅ #3: Logging kh√¥ng ƒë·∫ßy ƒë·ªß**
- Kh√¥ng log r√µ khi epoch ho√†n th√†nh
- Kh√¥ng log chi ti·∫øt tr·∫°ng th√°i checkpoint khi load
- Kh√≥ debug khi c√≥ v·∫•n ƒë·ªÅ

#### **V·∫•n ƒë·ªÅ #4: Progress bar g√¢y hi·ªÉu nh·∫ßm**
```python
progress_bar = tqdm(enumerate(self.train_loader), 
                    total=total_batches, 
                    initial=resume_step)
```
- V·ªõi `initial=1000`, tqdm b·∫Øt ƒë·∫ßu ƒë·∫øm t·ª´ 1000
- Nh∆∞ng v√≤ng l·∫∑p v·∫´n iterate qua T·∫§T C·∫¢ batches (t·ª´ 0 ƒë·∫øn 1269)
- Khi skip 1000 batches ƒë·∫ßu, progress bar v·∫´n tƒÉng m·ªói iteration
- Output "1812it" = 1000 (initial) + 812 (iterations)
- C√≥ th·ªÉ g√¢y hi·ªÉu l·∫ßm v·ªÅ s·ªë batches th·ª±c s·ª± ƒë∆∞·ª£c train

### 3. K·ªãch b·∫£n c√≥ th·ªÉ x·∫£y ra (gi·∫£i th√≠ch checkpoint epoch=1, step=1000):

**K·ªãch b·∫£n A: Epoch 1 ch∆∞a ho√†n th√†nh**
1. Train epoch 1 ƒë·∫øn step 1000
2. L∆∞u checkpoint (epoch=1, step=1000)
3. **Training b·ªã d·ª´ng** (user Ctrl+C, crash, out of memory, etc.)
4. Checkpoint cu·ªëi epoch kh√¥ng ƒë∆∞·ª£c l∆∞u
5. Resume ‚Üí Load checkpoint (epoch=1, step=1000)

**K·ªãch b·∫£n B: Checkpoint cu·ªëi epoch b·ªã fail**
1. Train epoch 1 ho√†n th√†nh (1270/1270 batches)
2. Ch·∫°y validation
3. C·ªë g·∫Øng l∆∞u checkpoint (epoch=1, step=0)
4. **Save FAILED** (Google Drive sync issue, permission, disk full, etc.)
5. Checkpoint v·∫´n l√† (epoch=1, step=1000) t·ª´ l·∫ßn l∆∞u tr∆∞·ªõc
6. Resume ‚Üí Load checkpoint (epoch=1, step=1000)

**K·ªãch b·∫£n C: Checkpoint b·ªã ghi ƒë√®**
1. Epoch 1 ho√†n th√†nh ‚Üí L∆∞u (epoch=1, step=0) ‚úÖ
2. Epoch 2 b·∫Øt ƒë·∫ßu
3. Epoch 2, step 500 ‚Üí L∆∞u (epoch=2, step=500) - GHI ƒê√à file
4. User rollback/restore Google Drive v·ªÅ version c≈©
5. Checkpoint quay v·ªÅ (epoch=1, step=1000)

## C√°c s·ª≠a ƒë·ªïi ƒë√£ th·ª±c hi·ªán:

### ‚úÖ S·ª≠a #1: Atomic checkpoint save v·ªõi error handling
- L∆∞u v√†o temp directory tr∆∞·ªõc
- Ch·ªâ move sang final location khi th√†nh c√¥ng
- T·∫°o backup tr∆∞·ªõc khi ghi ƒë√®
- Log chi ti·∫øt l·ªói n·∫øu save fail
- Kh√¥ng crash training n·∫øu save fail

### ‚úÖ S·ª≠a #2: Enhanced logging
- Log chi ti·∫øt khi load checkpoint (epoch, step, total_batches, completion status)
- Log r√µ r√†ng khi l∆∞u mid-epoch vs end-of-epoch checkpoint
- Log chi ti·∫øt logic resume (epoch ƒë√£ xong hay ch∆∞a)
- Th√™m visual indicators (‚úÖ, ‚è∏Ô∏è, ‚û°Ô∏è) ƒë·ªÉ d·ªÖ ƒë·ªçc

### ‚úÖ S·ª≠a #3: L∆∞u total_batches v√†o checkpoint
- Gi√∫p x√°c ƒë·ªãnh ch√≠nh x√°c epoch ƒë√£ ho√†n th√†nh hay ch∆∞a
- Ph√°t hi·ªán n·∫øu dataset size thay ƒë·ªïi gi·ªØa c√°c l·∫ßn ch·∫°y

### ‚úÖ S·ª≠a #4: Improved resume logic
- Ki·ªÉm tra `step >= total_batches` ƒë·ªÉ detect epoch ho√†n th√†nh
- Log r√µ r√†ng % progress n·∫øu mid-epoch
- Log s·ªë batches c√≤n l·∫°i

## Tools h·ªó tr·ª£ debug:

### scripts/debug_checkpoint.py
Ph√¢n t√≠ch chi ti·∫øt checkpoint state:
```bash
python scripts/debug_checkpoint.py --checkpoint_path /path/to/checkpoint
```

### scripts/fix_checkpoint_epoch.py
S·ª≠a th·ªß c√¥ng checkpoint ƒë·ªÉ ƒë√°nh d·∫•u epoch ƒë√£ xong:
```bash
python scripts/fix_checkpoint_epoch.py --checkpoint_path /path/to/checkpoint --epoch 1
```

## Khuy·∫øn ngh·ªã:

1. **Ki·ªÉm tra log chi ti·∫øt** c·ªßa l·∫ßn train tr∆∞·ªõc ƒë·ªÉ x√°c ƒë·ªãnh:
   - Epoch 1 c√≥ ho√†n th√†nh kh√¥ng (t√¨m "Epoch 1 COMPLETED" ho·∫∑c validation metrics)
   - C√≥ l·ªói n√†o khi save checkpoint kh√¥ng
   
2. **N·∫øu ch·∫Øc ch·∫Øn epoch 1 ƒë√£ xong:**
   - S·ª≠ d·ª•ng `scripts/fix_checkpoint_epoch.py` ƒë·ªÉ fix checkpoint
   - Ho·∫∑c x√≥a checkpoint v√† train l·∫°i t·ª´ ƒë·∫ßu

3. **Ki·ªÉm tra Google Drive sync** n·∫øu train tr√™n Colab:
   - ƒê·∫£m b·∫£o Drive c√≥ ƒë·ªß dung l∆∞·ª£ng
   - Ki·ªÉm tra file checkpoint c√≥ b·ªã conflict kh√¥ng
   - Xem Drive c√≥ message l·ªói sync kh√¥ng

4. **Monitoring trong l·∫ßn train ti·∫øp theo:**
   - Theo d√µi log "üì• Saving end-of-epoch checkpoint"
   - Ki·ªÉm tra "‚úÖ Checkpoint saved" confirmation
   - X√°c nh·∫≠n checkpoint state sau m·ªói epoch

## Log m·∫´u sau khi s·ª≠a:

```
============================================================
RESUMING TRAINING FROM CHECKPOINT
Checkpoint path: /content/drive/MyDrive/EnStack_Data/checkpoints/codebert/last_checkpoint
============================================================
============================================================
LOADED CHECKPOINT STATE:
  Epoch: 1
  Step: 1000
  Total Batches (saved): 1270
  Best Val F1: 0.0667
  Best Val Acc: 0.5000
  Status: ‚è∏Ô∏è  Epoch 1 INCOMPLETE (78.7% done)
============================================================

Current dataset: 1270 batches/epoch

‚è∏Ô∏è  Epoch 1 is INCOMPLETE
   Progress: 1000/1270 batches (78.7%)
   Remaining: 270 batches
‚û°Ô∏è  Will resume WITHIN epoch 1 from step 1000
============================================================

============================================================
STARTING TRAINING: 10 epochs (from epoch 1)
============================================================

============================================================
EPOCH 1/10
  Resuming from step 1000
============================================================
```

V·ªõi c√°c s·ª≠a ƒë·ªïi n√†y, user s·∫Ω th·∫•y r√µ r√†ng:
- Checkpoint hi·ªán t·∫°i ·ªü ƒë√¢u
- Epoch ƒë√£ ho√†n th√†nh hay ch∆∞a
- Training s·∫Ω resume t·ª´ ƒë√¢u
- N·∫øu c√≥ l·ªói khi save checkpoint
